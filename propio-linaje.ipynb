{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL ----\n",
      "insert into sbani.dest_table (id, nombre, telefono)\n",
      "        select t.id, t.full_name as nombre, t.phone from sbani.source_table t;\n",
      "Lineage JSON:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"21ebcd6e-0cd7-45de-ac0d-9bc516903f60\",\n",
      "    \"consulta\": \"insert into sbani.dest_table (id, nombre, telefono) select t.id, t.full_name as nombre, t.phone from sbani.source_table t\",\n",
      "    \"tabla_origen\": \"sbani.source_table\",\n",
      "    \"tabla_destino\": \"sbani.dest_table\",\n",
      "    \"campo_origen\": \"id\",\n",
      "    \"campo_destino\": \"id\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping por posicion entre select y lista de columnas destino\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"fdaac121-4567-4a66-b372-8fcc6e8d1553\",\n",
      "    \"consulta\": \"insert into sbani.dest_table (id, nombre, telefono) select t.id, t.full_name as nombre, t.phone from sbani.source_table t\",\n",
      "    \"tabla_origen\": \"sbani.source_table\",\n",
      "    \"tabla_destino\": \"sbani.dest_table\",\n",
      "    \"campo_origen\": \"full_name\",\n",
      "    \"campo_destino\": \"nombre\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping por posicion entre select y lista de columnas destino\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"9e3de200-e0a1-43a1-b9b5-2346e6c67808\",\n",
      "    \"consulta\": \"insert into sbani.dest_table (id, nombre, telefono) select t.id, t.full_name as nombre, t.phone from sbani.source_table t\",\n",
      "    \"tabla_origen\": \"sbani.source_table\",\n",
      "    \"tabla_destino\": \"sbani.dest_table\",\n",
      "    \"campo_origen\": \"phone\",\n",
      "    \"campo_destino\": \"telefono\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping por posicion entre select y lista de columnas destino\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "\n",
      "SQL ----\n",
      "insert into sbani.dest_all\n",
      "        select * from sbani.source_all;\n",
      "Lineage JSON:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"59a3b3c6-3bc9-441a-a37d-83930cf145f7\",\n",
      "    \"consulta\": \"insert into sbani.dest_all select * from sbani.source_all\",\n",
      "    \"tabla_origen\": \"sbani.source_all\",\n",
      "    \"tabla_destino\": \"sbani.dest_all\",\n",
      "    \"campo_origen\": null,\n",
      "    \"campo_destino\": null,\n",
      "    \"transformacion_aplicada\": null,\n",
      "    \"recomendaciones\": \"relacion a nivel de tablas por uso de * en el select; si necesita mapping columna a columna, especificar columnas en el insert o consultar metastore\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "\n",
      "SQL ----\n",
      "create table sbani.ctas_table as\n",
      "        select a.col1, b.col2 from sbani.tabla_a a join sbani.tabla_b b on a.id = b.id;\n",
      "Lineage JSON:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"59b16f54-4313-4720-a38e-3981a8d885a5\",\n",
      "    \"consulta\": \"create table sbani.ctas_table as select a.col1, b.col2 from sbani.tabla_a a join sbani.tabla_b b on a.id = b.id\",\n",
      "    \"tabla_origen\": \"sbani.tabla_a\",\n",
      "    \"tabla_destino\": \"sbani.ctas_table\",\n",
      "    \"campo_origen\": \"col1\",\n",
      "    \"campo_destino\": \"col1\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping inferido sin lista destino; se recomienda especificar columnas en create table (...) as select (...) para mayor precisiã³n\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"6eaa76c1-6d61-430f-85d7-b421e4d82a78\",\n",
      "    \"consulta\": \"create table sbani.ctas_table as select a.col1, b.col2 from sbani.tabla_a a join sbani.tabla_b b on a.id = b.id\",\n",
      "    \"tabla_origen\": \"sbani.tabla_b\",\n",
      "    \"tabla_destino\": \"sbani.ctas_table\",\n",
      "    \"campo_origen\": \"col2\",\n",
      "    \"campo_destino\": \"col2\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping inferido sin lista destino; se recomienda especificar columnas en create table (...) as select (...) para mayor precisiã³n\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "\n",
      "SQL ----\n",
      "with cte as (\n",
      "           select id, valor from sbani.origen\n",
      "        )\n",
      "        insert into sbani.destino select id, valor from cte;\n",
      "Lineage JSON:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"94560c34-72df-45ab-8696-6e83681bab3f\",\n",
      "    \"consulta\": \"with cte as ( select id, valor from sbani.origen ) insert into sbani.destino select id, valor from cte\",\n",
      "    \"tabla_origen\": null,\n",
      "    \"tabla_destino\": \"sbani.destino\",\n",
      "    \"campo_origen\": \"id\",\n",
      "    \"campo_destino\": \"id\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping inferido sin lista destino; se recomienda especificar columnas en el insert para mayor claridad\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"9cf74307-72ba-40aa-85a0-9f51ecea2298\",\n",
      "    \"consulta\": \"with cte as ( select id, valor from sbani.origen ) insert into sbani.destino select id, valor from cte\",\n",
      "    \"tabla_origen\": null,\n",
      "    \"tabla_destino\": \"sbani.destino\",\n",
      "    \"campo_origen\": \"valor\",\n",
      "    \"campo_destino\": \"valor\",\n",
      "    \"transformacion_aplicada\": \"copy\",\n",
      "    \"recomendaciones\": \"mapping inferido sin lista destino; se recomienda especificar columnas en el insert para mayor claridad\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generador de linaje (impala sql) - python\n",
    "Salida: lista de dicts (json-serializable) con los campos:\n",
    "id, consulta, tabla_origen, tabla_destino, campo_origen, campo_destino, transformacion_aplicada, recomendaciones\n",
    "\n",
    "Notas:\n",
    "- todo en minÃºsculas\n",
    "- heurÃ­stico: intenta manejar insert/select, create as select, with ... insert ... as\n",
    "- si detecta '*' o 'table.*' genera relaciones a nivel tabla\n",
    "- comentarÃ© el cÃ³digo paso a paso (en espaÃ±ol)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# Helpers de anÃ¡lisis lÃ©xico simples (manejan parÃ©ntesis y comillas)\n",
    "# -------------------------\n",
    "\n",
    "def normalize_sql(sql: str) -> str:\n",
    "    \"\"\"Normaliza: pasa a minÃºsculas y colapsa espacios (no altera comillas internas).\"\"\"\n",
    "    # conservamos comillas pero simplificamos espacios\n",
    "    s = sql.strip()\n",
    "    # convertimos a minÃºsculas (impala no distingue mayÃºsculas para keywords)\n",
    "    s = s.lower()\n",
    "    # colapsar mÃºltiples espacios, tab y saltos de lÃ­nea en un Ãºnico espacio\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "\n",
    "def top_level_split(s: str, delimiter: str=',') -> list:\n",
    "    \"\"\"\n",
    "    Divide una cadena por delimitador pero solo en nivel superior (depth==0).\n",
    "    Maneja comillas simples y dobles y parÃ©ntesis.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    cur = []\n",
    "    depth = 0\n",
    "    in_s = False\n",
    "    in_d = False\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        ch = s[i]\n",
    "        # manejo de comillas (no interpretamos escapes)\n",
    "        if ch == \"'\" and not in_d:\n",
    "            in_s = not in_s\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if ch == '\"' and not in_s:\n",
    "            in_d = not in_d\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if in_s or in_d:\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if ch == ')':\n",
    "            if depth > 0:\n",
    "                depth -= 1\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if ch == delimiter and depth == 0:\n",
    "            parts.append(''.join(cur).strip())\n",
    "            cur = []\n",
    "            i += 1\n",
    "            continue\n",
    "        cur.append(ch)\n",
    "        i += 1\n",
    "    last = ''.join(cur).strip()\n",
    "    if last:\n",
    "        parts.append(last)\n",
    "    return parts\n",
    "\n",
    "def find_top_level_keyword(s: str, keyword: str, start: int=0) -> int:\n",
    "    \"\"\"\n",
    "    Busca la posiciÃ³n de la palabra keyword a nivel top (no dentro de parÃ©ntesis ni comillas).\n",
    "    Retorna Ã­ndice o -1 si no encuentra.\n",
    "    \"\"\"\n",
    "    keyword = keyword.lower()\n",
    "    i = start\n",
    "    depth = 0\n",
    "    in_s = False\n",
    "    in_d = False\n",
    "    L = len(s)\n",
    "    while i < L:\n",
    "        ch = s[i]\n",
    "        if ch == \"'\" and not in_d:\n",
    "            in_s = not in_s; i += 1; continue\n",
    "        if ch == '\"' and not in_s:\n",
    "            in_d = not in_d; i += 1; continue\n",
    "        if in_s or in_d:\n",
    "            i += 1; continue\n",
    "        if ch == '(':\n",
    "            depth += 1; i += 1; continue\n",
    "        if ch == ')':\n",
    "            if depth > 0: depth -= 1\n",
    "            i += 1; continue\n",
    "        # si estamos en nivel top, probar si keyword encaja acÃ¡\n",
    "        if depth == 0:\n",
    "            if s.startswith(keyword, i):\n",
    "                # verificar fronteras de palabra (-1 o no alfanumÃ©rico antes y despuÃ©s)\n",
    "                before = s[i-1] if i-1 >= 0 else ' '\n",
    "                after_pos = i + len(keyword)\n",
    "                after = s[after_pos] if after_pos < L else ' '\n",
    "                if (not before.isalnum()) and (not after.isalnum()):\n",
    "                    return i\n",
    "        i += 1\n",
    "    return -1\n",
    "\n",
    "def split_statements_top_level(sql: str) -> list:\n",
    "    \"\"\"Divide mÃºltiples sentencias separadas por ; a nivel top.\"\"\"\n",
    "    parts = []\n",
    "    cur = []\n",
    "    depth = 0\n",
    "    in_s = False\n",
    "    in_d = False\n",
    "    i = 0\n",
    "    while i < len(sql):\n",
    "        ch = sql[i]\n",
    "        if ch == \"'\" and not in_d:\n",
    "            in_s = not in_s; cur.append(ch); i += 1; continue\n",
    "        if ch == '\"' and not in_s:\n",
    "            in_d = not in_d; cur.append(ch); i += 1; continue\n",
    "        if in_s or in_d:\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if ch == '(':\n",
    "            depth += 1; cur.append(ch); i += 1; continue\n",
    "        if ch == ')':\n",
    "            if depth > 0: depth -= 1\n",
    "            cur.append(ch); i += 1; continue\n",
    "        if ch == ';' and depth == 0:\n",
    "            stmt = ''.join(cur).strip()\n",
    "            if stmt:\n",
    "                parts.append(stmt)\n",
    "            cur = []\n",
    "            i += 1\n",
    "            continue\n",
    "        cur.append(ch)\n",
    "        i += 1\n",
    "    last = ''.join(cur).strip()\n",
    "    if last:\n",
    "        parts.append(last)\n",
    "    return parts\n",
    "\n",
    "# -------------------------\n",
    "# ExtracciÃ³n de partes principales\n",
    "# -------------------------\n",
    "\n",
    "def extract_select_range(stmt: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Retorna (select_start_idx, select_end_idx) donde select_end es la posiciÃ³n del 'from' top-level correspondiente.\n",
    "    Si no hay 'select' o 'from' adecuados retorna (-1, -1).\n",
    "    \"\"\"\n",
    "    sel_pos = find_top_level_keyword(stmt, 'select', 0)\n",
    "    if sel_pos == -1:\n",
    "        return -1, -1\n",
    "    # buscamos el FROM top-level que siga\n",
    "    from_pos = find_top_level_keyword(stmt, 'from', sel_pos + len('select'))\n",
    "    if from_pos == -1:\n",
    "        return sel_pos, -1\n",
    "    return sel_pos, from_pos\n",
    "\n",
    "def extract_select_items(stmt: str) -> list:\n",
    "    \"\"\"\n",
    "    Extrae la lista de items del SELECT (entre select y from) en nivel top y los separa por comas top-level.\n",
    "    \"\"\"\n",
    "    sel_pos, from_pos = extract_select_range(stmt)\n",
    "    if sel_pos == -1 or from_pos == -1:\n",
    "        return []\n",
    "    select_str = stmt[sel_pos + len('select'): from_pos].strip()\n",
    "    items = top_level_split(select_str, delimiter=',')\n",
    "    return [it.strip() for it in items if it.strip()]\n",
    "\n",
    "def extract_from_clause(stmt: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrae el fragmento 'from ...' hasta la siguiente palabra clave top-level (where, group, order, having, limit, union).\n",
    "    \"\"\"\n",
    "    sel_pos, from_pos = extract_select_range(stmt)\n",
    "    if from_pos == -1:\n",
    "        return ''\n",
    "    start = from_pos + len('from')\n",
    "    # buscar prÃ³xima palabra clave top-level\n",
    "    keywords = ['where', 'group', 'having', 'order', 'limit', 'union', 'insert', ';']\n",
    "    next_pos = len(stmt)\n",
    "    for k in keywords:\n",
    "        p = find_top_level_keyword(stmt, k, start)\n",
    "        if p != -1 and p < next_pos:\n",
    "            next_pos = p\n",
    "    return stmt[start:next_pos].strip()\n",
    "\n",
    "def extract_tables_from_from_clause(from_clause: str) -> list:\n",
    "    \"\"\"\n",
    "    Extrae nombres de tablas calificados tipo schema.tabla desde el from/join fragment.\n",
    "    Devuelve lista de (tabla_completa, alias_o_none).\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    # separa por joins y comas top-level\n",
    "    # reemplazamos ' join ' por ', ' para poder splittear por comas top-level\n",
    "    # pero mantendremos parÃ©ntesis manejados por top_level_split\n",
    "    # para simplificar, covertimos las palabras join en ',' y luego top_level_split por ','\n",
    "    # sin embargo, debemos preservar subqueries entre parÃ©ntesis; top_level_split lo harÃ¡ bien.\n",
    "    # sustituimos palabras clave join por comas solo a nivel texto (no afecta parÃ©ntesis)\n",
    "    norm = re.sub(r'\\b(left|right|inner|outer|full)\\s+join\\b', ' join', from_clause)\n",
    "    # ahora sustituir ' join ' y ' on ' por comas para separar bloques\n",
    "    tmp = re.sub(r'\\bjoin\\b', ',', norm)\n",
    "    tmp = re.sub(r'\\bon\\b.*', '', tmp)  # eliminar condiciones ON (simplifica)\n",
    "    parts = top_level_split(tmp, delimiter=',')\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        # buscar pattern schema.table (ej. sbani.tablacontacta)\n",
    "        m = re.search(r'([a-z0-9_]+\\.[a-z0-9_]+)', p)\n",
    "        if m:\n",
    "            tabla = m.group(1)\n",
    "            # buscar alias (as alias o simple alias)\n",
    "            alias = None\n",
    "            # buscar ' as alias'\n",
    "            m2 = re.search(r'\\b' + re.escape(tabla) + r'\\b\\s+(?:as\\s+)?([a-z0-9_]+)', p)\n",
    "            if m2:\n",
    "                alias = m2.group(1)\n",
    "            res.append((tabla, alias))\n",
    "    return res\n",
    "\n",
    "def resolve_table_from_token(token: str, src_tables: list) -> str:\n",
    "    \"\"\"\n",
    "    Dado un token tipo 't.id', 'schema.tabla.id', 'tabla.id' o 'tabla',\n",
    "    devuelve el nombre completo 'schema.tabla' resolviendo alias si corresponde.\n",
    "    Retorna None si no se puede determinar.\n",
    "    \"\"\"\n",
    "    if not token or token == '*':\n",
    "        return None\n",
    "    # construir mapas de alias y de nombre base de tabla -> nombre completo\n",
    "    alias_map = {alias: full for (full, alias) in src_tables if alias}\n",
    "    base_map = {}\n",
    "    for (full, alias) in src_tables:\n",
    "        base = full.split('.')[-1]\n",
    "        if base not in base_map:\n",
    "            base_map[base] = full\n",
    "    parts = token.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        first, second = parts[0], parts[1]\n",
    "        # si 'first' es alias conocido\n",
    "        if first in alias_map:\n",
    "            return alias_map[first]\n",
    "        # si 'first.second' ya es un nombre completo de tabla\n",
    "        cand = first + '.' + second\n",
    "        for (full, _) in src_tables:\n",
    "            if full == cand:\n",
    "                return cand\n",
    "        # si 'first' coincide con el nombre base de alguna tabla\n",
    "        if first in base_map:\n",
    "            return base_map[first]\n",
    "    else:\n",
    "        first = parts[0]\n",
    "        if first in alias_map:\n",
    "            return alias_map[first]\n",
    "        if first in base_map:\n",
    "            return base_map[first]\n",
    "        # si es solo un nombre de columna y solo hay una tabla fuente, asumimos esa tabla\n",
    "        fulls = [full for (full, _) in src_tables]\n",
    "        uniques = []\n",
    "        for f in fulls:\n",
    "            if f not in uniques:\n",
    "                uniques.append(f)\n",
    "        if len(uniques) == 1:\n",
    "            return uniques[0]\n",
    "    # fallback global: si no se pudo resolver y hay una sola tabla fuente\n",
    "    fulls = [full for (full, _) in src_tables]\n",
    "    uniques = []\n",
    "    for f in fulls:\n",
    "        if f not in uniques:\n",
    "            uniques.append(f)\n",
    "    if len(uniques) == 1:\n",
    "        return uniques[0]\n",
    "    return None\n",
    "\n",
    "def parse_ctes(stmt: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extrae definiciones de CTE a partir de una sentencia que comienza con WITH.\n",
    "    Devuelve dict nombre_cte -> texto_select_de_cte\n",
    "    \"\"\"\n",
    "    cte_map = {}\n",
    "    if not stmt.strip().startswith('with '):\n",
    "        return cte_map\n",
    "    pos_insert = find_top_level_keyword(stmt, 'insert', 0)\n",
    "    pos_create = find_top_level_keyword(stmt, 'create', 0)\n",
    "    pos_select = find_top_level_keyword(stmt, 'select', 0)\n",
    "    candidates = [p for p in [pos_insert, pos_create, pos_select] if p and p > 0]\n",
    "    if not candidates:\n",
    "        return cte_map\n",
    "    main_pos = min(candidates)\n",
    "    defs_str = stmt[len('with '):main_pos].strip()\n",
    "    if not defs_str:\n",
    "        return cte_map\n",
    "    defs = top_level_split(defs_str, delimiter=',')\n",
    "    for d in defs:\n",
    "        d = d.strip()\n",
    "        m = re.match(r'([a-z0-9_]+)\\s+as\\s*\\((.*)\\)$', d)\n",
    "        if not m:\n",
    "            continue\n",
    "        name = m.group(1)\n",
    "        body = m.group(2).strip()\n",
    "        cte_map[name] = body\n",
    "    return cte_map\n",
    "\n",
    "def get_src_tables_with_ctes(from_clause: str, cte_map: dict) -> list:\n",
    "    \"\"\"\n",
    "    Retorna tablas fuente incluyendo expansiÃ³n de CTEs referenciados en el from_clause.\n",
    "    \"\"\"\n",
    "    src_tables = extract_tables_from_from_clause(from_clause)\n",
    "    if not cte_map:\n",
    "        return src_tables\n",
    "    # por cada CTE, si es referenciado, aÃ±adimos sus tablas fÃ­sicas como si fueran parte del FROM\n",
    "    for cte_name, cte_sql in cte_map.items():\n",
    "        # detectar uso del CTE y posible alias\n",
    "        m = re.search(r'\\b' + re.escape(cte_name) + r'\\b(?:\\s+(?:as\\s+)?([a-z0-9_]+))?', from_clause)\n",
    "        if not m:\n",
    "            continue\n",
    "        cte_alias = m.group(1) if m.group(1) else cte_name\n",
    "        inner_from = extract_from_clause(cte_sql)\n",
    "        inner_tables = extract_tables_from_from_clause(inner_from)\n",
    "        for (full, _alias) in inner_tables:\n",
    "            src_tables.append((full, cte_alias))\n",
    "    return src_tables\n",
    "\n",
    "# -------------------------\n",
    "# Parseo de target table y columnas (insert/create)\n",
    "# -------------------------\n",
    "\n",
    "def parse_insert_target(stmt: str):\n",
    "    \"\"\"\n",
    "    Detecta target en sentencias insert ... into\n",
    "    Retorna (tabla_destino, [lista_columnas] o None)\n",
    "    \"\"\"\n",
    "    # buscar 'insert' top-level\n",
    "    ins_pos = find_top_level_keyword(stmt, 'insert', 0)\n",
    "    if ins_pos == -1:\n",
    "        return None, None\n",
    "    # buscar 'into' despuÃ©s de insert\n",
    "    into_pos = find_top_level_keyword(stmt, 'into', ins_pos)\n",
    "    # hay casos 'insert overwrite' -> handle: buscar 'overwrite' y luego 'into'\n",
    "    if into_pos == -1:\n",
    "        # tal vez 'insert overwrite table <table>' => buscamos 'table' o directamente schema.table\n",
    "        # fallback: buscar primer schema.table despuÃ©s de insert\n",
    "        m = re.search(r'([a-z0-9_]+\\.[a-z0-9_]+)', stmt[ins_pos:])\n",
    "        if m:\n",
    "            tabla = m.group(1)\n",
    "            # ver si hay lista de columnas entre parÃ©ntesis justo despuÃ©s\n",
    "            after = stmt[ins_pos + m.end():]\n",
    "            col_m = re.match(r'\\s*\\(\\s*([^)]+)\\)', after)\n",
    "            if col_m:\n",
    "                cols = [c.strip() for c in col_m.group(1).split(',')]\n",
    "                return tabla, cols\n",
    "            return tabla, None\n",
    "        return None, None\n",
    "    # a partir de into, saltar espacios y palabra 'table' si existe\n",
    "    i = into_pos + len('into')\n",
    "    rest = stmt[i:].lstrip()\n",
    "    # si viene 'table' como palabra (impala a veces)\n",
    "    if rest.startswith('table '):\n",
    "        rest = rest[len('table '):].lstrip()\n",
    "    # ahora tomar nombre de tabla (schema.table)\n",
    "    m = re.match(r'([a-z0-9_]+\\.[a-z0-9_]+)', rest)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    tabla = m.group(1)\n",
    "    after = rest[m.end():].lstrip()\n",
    "    # si next char es '(' => lista de columnas destino\n",
    "    if after.startswith('('):\n",
    "        # extraer contenido hasta ')'\n",
    "        depth = 0\n",
    "        cols = []\n",
    "        cur = []\n",
    "        j = 0\n",
    "        while j < len(after):\n",
    "            ch = after[j]\n",
    "            if ch == '(':\n",
    "                depth += 1\n",
    "                if depth == 1:\n",
    "                    j += 1; continue\n",
    "            if ch == ')':\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    break\n",
    "            cur.append(ch)\n",
    "            j += 1\n",
    "        cols_str = ''.join(cur).strip()\n",
    "        cols = [c.strip() for c in cols_str.split(',') if c.strip()]\n",
    "        return tabla, cols\n",
    "    return tabla, None\n",
    "\n",
    "def parse_create_target(stmt: str):\n",
    "    \"\"\"\n",
    "    Detecta target en create table ... as select\n",
    "    Retorna (tabla_destino, [lista_columnas] o None, is_ctas_bool)\n",
    "    \"\"\"\n",
    "    # buscar create top-level\n",
    "    cr_pos = find_top_level_keyword(stmt, 'create', 0)\n",
    "    if cr_pos == -1:\n",
    "        return None, None, False\n",
    "    # buscar 'table' top-level despuÃ©s de create\n",
    "    tpos = find_top_level_keyword(stmt, 'table', cr_pos)\n",
    "    if tpos == -1:\n",
    "        return None, None, False\n",
    "    # buscar nombre de tabla\n",
    "    rest = stmt[tpos + len('table'):].lstrip()\n",
    "    # soportar 'if not exists'\n",
    "    if rest.startswith('if not exists'):\n",
    "        rest = rest[len('if not exists'):].lstrip()\n",
    "    m = re.match(r'([a-z0-9_]+\\.[a-z0-9_]+)', rest)\n",
    "    if not m:\n",
    "        return None, None, False\n",
    "    tabla = m.group(1)\n",
    "    after = rest[m.end():].lstrip()\n",
    "    # si hay parÃ©ntesis con columnas explÃ­citas: create table t (c1, c2) as select ...\n",
    "    if after.startswith('('):\n",
    "        # extraer hasta ')'\n",
    "        depth = 0; cur = []; j = 0\n",
    "        while j < len(after):\n",
    "            ch = after[j]\n",
    "            if ch == '(':\n",
    "                depth += 1\n",
    "                if depth == 1:\n",
    "                    j += 1; continue\n",
    "            if ch == ')':\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    break\n",
    "            cur.append(ch)\n",
    "            j += 1\n",
    "        cols_str = ''.join(cur).strip()\n",
    "        cols = [c.strip() for c in cols_str.split(',') if c.strip()]\n",
    "    else:\n",
    "        cols = None\n",
    "    # determinar si es CTAS (as select)\n",
    "    as_pos = find_top_level_keyword(stmt, 'as', tpos)\n",
    "    select_pos = find_top_level_keyword(stmt, 'select', tpos)\n",
    "    is_ctas = (as_pos != -1 and select_pos != -1 and as_pos < select_pos)\n",
    "    return tabla, cols, is_ctas\n",
    "\n",
    "# -------------------------\n",
    "# Parse de items SELECT -> extraer origen de columna y alias\n",
    "# -------------------------\n",
    "\n",
    "def parse_select_item(item: str) -> dict:\n",
    "    \"\"\"\n",
    "    Dado un item del select devuelve:\n",
    "    {\n",
    "      'raw': item,\n",
    "      'origin_cols': [maybe one or more origen como 'schema.tbl.col' o 'col'],\n",
    "      'alias': alias o None,\n",
    "      'expr': expression (texto),\n",
    "      'is_star': True/False\n",
    "    }\n",
    "    \"\"\"\n",
    "    res = {'raw': item, 'origin_cols': [], 'alias': None, 'expr': item.strip(), 'is_star': False}\n",
    "    it = item.strip()\n",
    "    # detectar aliases con ' as alias' o ' expr alias'\n",
    "    # buscamos la presencia de ' as ' al top-level\n",
    "    # simplificamos: si hay ' as ' la parte despuÃ©s es alias\n",
    "    m_as = re.search(r'\\s+as\\s+([a-z0-9_]+)\\s*$', it)\n",
    "    if m_as:\n",
    "        alias = m_as.group(1)\n",
    "        expr = it[:m_as.start()].strip()\n",
    "        res['alias'] = alias\n",
    "        res['expr'] = expr\n",
    "        it = expr\n",
    "    else:\n",
    "        # si no hay 'as', puede existir 'expr alias' -> detectamos Ãºltimo token simple al final\n",
    "        m_alias2 = re.search(r'\\s+([a-z0-9_]+)\\s*$', it)\n",
    "        if m_alias2:\n",
    "            # para no confundir functions o 'case when', sÃ³lo tomamos alias si la parte antes no termina con un parÃ©ntesis ni contiene espacios raros\n",
    "            before = it[:m_alias2.start()].strip()\n",
    "            last_tok = m_alias2.group(1)\n",
    "            # heurÃ­stica: si before contiene espacios y no termina en ')' o es una expresiÃ³n sencilla, consideramos alias\n",
    "            if re.search(r'\\s', before) and not before.endswith(')') and not before.endswith(']'):\n",
    "                res['alias'] = last_tok\n",
    "                res['expr'] = before\n",
    "                it = before\n",
    "    # detectar star\n",
    "    if re.match(r'^\\*$', it) or re.match(r'^[a-z0-9_]+\\.\\*$', it):\n",
    "        res['is_star'] = True\n",
    "        # si es table.* extraer la tabla\n",
    "        if '.' in it:\n",
    "            res['origin_cols'] = [it]  # e.g. sbani.tabla.*\n",
    "        else:\n",
    "            res['origin_cols'] = ['*']\n",
    "        return res\n",
    "    # extraer columnas simples de la expresiÃ³n: buscar patrones schema.tab.col o table.col o bare col\n",
    "    # bÃºsqueda de formatos schema.table.col o table.col o col\n",
    "    # buscar todos los identificadores separados por punto\n",
    "    col_refs = re.findall(r'([a-z0-9_]+\\.[a-z0-9_]+\\.[a-z0-9_]+|[a-z0-9_]+\\.[a-z0-9_]+|[a-z0-9_]+)', it)\n",
    "    # col_refs incluye tokens y palabras; no todos son columnas; filtramos palabras reservadas y functions comunes\n",
    "    keywords = set(['case','when','then','else','end','count','sum','min','max','avg','cast'])\n",
    "    cols = []\n",
    "    for token in col_refs:\n",
    "        if token in keywords:\n",
    "            continue\n",
    "        # token que tiene punto puede ser table.col o schema.table (si tiene dos puntos lo dejamos)\n",
    "        # heurÃ­stica: si token coincide con funcname(...) no lo incluimos (pero el regex ya saca solo nombres)\n",
    "        cols.append(token)\n",
    "    # preferimos detectar referencias columna tipo table.col o schema.table.col\n",
    "    res['origin_cols'] = cols\n",
    "    return res\n",
    "\n",
    "# -------------------------\n",
    "# Construir mapeos de linaje por sentencia\n",
    "# -------------------------\n",
    "\n",
    "def lineage_from_statement(stmt: str, cte_map: dict=None) -> list:\n",
    "    \"\"\"\n",
    "    Dada una sentencia SQL (normalizada en lowercase), retorna lista de registros de linaje (dicts).\n",
    "    \"\"\"\n",
    "    stmt = stmt.strip()\n",
    "    cte_map = cte_map or {}\n",
    "    results = []\n",
    "    # primero detectar si es create table ... as select (ctas)\n",
    "    tabla_create, cols_create, is_ctas = parse_create_target(stmt)\n",
    "    if is_ctas and tabla_create:\n",
    "        # CTAS: tabla destino = tabla_create\n",
    "        target_table = tabla_create\n",
    "        target_cols = cols_create  # puede ser None\n",
    "        select_items = extract_select_items(stmt)\n",
    "        from_clause = extract_from_clause(stmt)\n",
    "        src_tables = get_src_tables_with_ctes(from_clause, cte_map)\n",
    "        # si select_items contiene alguna star o no se especifican columnas destino -> relaciÃ³n tabla->tabla\n",
    "        has_star = any(('*' in it) for it in select_items)\n",
    "        if has_star or target_cols is None and (len(select_items) == 0 or any(item.strip() == '' for item in select_items)):\n",
    "            # relaciÃ³n a nivel tabla: por las reglas del usuario, si se crea tabla en base al esquema de otra y no se indican campos -> tabla->tabla\n",
    "            for (src_tab, alias) in src_tables:\n",
    "                rec = {\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'consulta': stmt,\n",
    "                    'tabla_origen': src_tab,\n",
    "                    'tabla_destino': target_table,\n",
    "                    'campo_origen': None,\n",
    "                    'campo_destino': None,\n",
    "                    'transformacion_aplicada': None,\n",
    "                    'recomendaciones': 'relacion a nivel de tablas (ctas sin lista de campos o uso de *) - verificar esquema en metastore si necesita mapping columna a columna'\n",
    "                }\n",
    "                results.append(rec)\n",
    "            # si no hay src_tables detectadas, crear un registro general\n",
    "            if not src_tables:\n",
    "                rec = {\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'consulta': stmt,\n",
    "                    'tabla_origen': None,\n",
    "                    'tabla_destino': target_table,\n",
    "                    'campo_origen': None,\n",
    "                    'campo_destino': None,\n",
    "                    'transformacion_aplicada': None,\n",
    "                    'recomendaciones': 'relacion a nivel de tablas (ctas sin lista de campos) - no se detectaron tablas origen'\n",
    "                }\n",
    "                results.append(rec)\n",
    "        else:\n",
    "            # mapeo columna a columna (intentar inferir)\n",
    "            items = [parse_select_item(it) for it in select_items]\n",
    "            # si target_cols estÃ¡ definido, mapear por posiciÃ³n\n",
    "            if target_cols:\n",
    "                for idx, item in enumerate(items):\n",
    "                    dest_col = target_cols[idx] if idx < len(target_cols) else None\n",
    "                    origin = None\n",
    "                    if item['origin_cols']:\n",
    "                        origin = item['origin_cols'][-1]  # heurÃ­stica: ultima referencia\n",
    "                    transform = None\n",
    "                    if item['is_star']:\n",
    "                        origin = '*'\n",
    "                        transform = None\n",
    "                    else:\n",
    "                        # si expr es exactamente origin (ej table.col) => copy\n",
    "                        if len(item['origin_cols']) == 1 and item['expr'].strip() in item['origin_cols']:\n",
    "                            transform = 'copy'\n",
    "                        else:\n",
    "                            transform = item['expr']\n",
    "                    rec = {\n",
    "                        'id': str(uuid.uuid4()),\n",
    "                        'consulta': stmt,\n",
    "                        'tabla_origen': resolve_table_from_token(origin if origin else (item['origin_cols'][-1] if item['origin_cols'] else None), src_tables),\n",
    "                        'tabla_destino': target_table,\n",
    "                        'campo_origen': (origin if (not origin or origin=='*') else origin.split('.')[-1]),\n",
    "                        'campo_destino': (dest_col if (not dest_col or dest_col=='*') else dest_col.split('.')[-1]),\n",
    "                        'transformacion_aplicada': transform,\n",
    "                        'recomendaciones': 'verificar expresiones y tipos; mapping inferido por posicion en ctas con columnas destino'\n",
    "                    }\n",
    "                    if rec['tabla_origen'] is None and src_tables:\n",
    "                        _u = []\n",
    "                        for (_f,_a) in src_tables:\n",
    "                            if _f not in _u:\n",
    "                                _u.append(_f)\n",
    "                        if len(_u) == 1:\n",
    "                            rec['tabla_origen'] = _u[0]\n",
    "                    results.append(rec)\n",
    "            else:\n",
    "                # no hay columnas destino; usamos alias o nombre inferido en select\n",
    "                for item in items:\n",
    "                    dest_col = item['alias'] if item['alias'] else (item['origin_cols'][-1] if item['origin_cols'] else None)\n",
    "                    origin = None\n",
    "                    if item['origin_cols']:\n",
    "                        origin = item['origin_cols'][-1]\n",
    "                    transform = None\n",
    "                    if item['is_star']:\n",
    "                        origin = '*'\n",
    "                        transform = None\n",
    "                    else:\n",
    "                        if len(item['origin_cols']) == 1 and item['expr'].strip() in item['origin_cols']:\n",
    "                            transform = 'copy'\n",
    "                        else:\n",
    "                            transform = item['expr']\n",
    "                    rec = {\n",
    "                        'id': str(uuid.uuid4()),\n",
    "                        'consulta': stmt,\n",
    "                        'tabla_origen': resolve_table_from_token(origin if origin else (item['origin_cols'][-1] if item['origin_cols'] else None), src_tables),\n",
    "                        'tabla_destino': target_table,\n",
    "                        'campo_origen': (origin if (not origin or origin=='*') else origin.split('.')[-1]),\n",
    "                        'campo_destino': (dest_col if (not dest_col or dest_col=='*') else dest_col.split('.')[-1]),\n",
    "                        'transformacion_aplicada': transform,\n",
    "                        'recomendaciones': 'mapping inferido sin lista destino; se recomienda especificar columnas en create table (...) as select (...) para mayor precisiÃ³n'\n",
    "                    }\n",
    "                    results.append(rec)\n",
    "        return results\n",
    "\n",
    "    # -------------------------\n",
    "    # Caso INSERT ... SELECT\n",
    "    # -------------------------\n",
    "    tabla_insert, cols_insert = parse_insert_target(stmt)\n",
    "    if tabla_insert:\n",
    "        target_table = tabla_insert\n",
    "        target_cols = cols_insert  # None o lista\n",
    "        select_items = extract_select_items(stmt)\n",
    "        from_clause = extract_from_clause(stmt)\n",
    "        src_tables = get_src_tables_with_ctes(from_clause, cte_map)\n",
    "        # parse items\n",
    "        items = [parse_select_item(it) for it in select_items]\n",
    "        # si existe algÃºn item is_star => relaciÃ³n tabla->tabla\n",
    "        any_star = any(it['is_star'] for it in items)\n",
    "        if any_star:\n",
    "            # cuando hay '*' en el select sin conocer campos, mantÃ©n relaciÃ³n a nivel de tablas\n",
    "            for (src_tab, alias) in src_tables:\n",
    "                rec = {\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'consulta': stmt,\n",
    "                    'tabla_origen': src_tab,\n",
    "                    'tabla_destino': target_table,\n",
    "                    'campo_origen': None,\n",
    "                    'campo_destino': None,\n",
    "                    'transformacion_aplicada': None,\n",
    "                    'recomendaciones': 'relacion a nivel de tablas por uso de * en el select; si necesita mapping columna a columna, especificar columnas en el insert o consultar metastore'\n",
    "                }\n",
    "                results.append(rec)\n",
    "            if not src_tables:\n",
    "                rec = {\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'consulta': stmt,\n",
    "                    'tabla_origen': None,\n",
    "                    'tabla_destino': target_table,\n",
    "                    'campo_origen': None,\n",
    "                    'campo_destino': None,\n",
    "                    'transformacion_aplicada': None,\n",
    "                    'recomendaciones': 'relacion a nivel de tablas por uso de *; no se detectaron tablas origen'\n",
    "                }\n",
    "                results.append(rec)\n",
    "            return results\n",
    "        # No hay stars -> intentamos mapear columnas\n",
    "        if target_cols:\n",
    "            # mapear por posiciÃ³n\n",
    "            for idx, item in enumerate(items):\n",
    "                dest_col = target_cols[idx] if idx < len(target_cols) else None\n",
    "                origin = None\n",
    "                if item['origin_cols']:\n",
    "                    origin = item['origin_cols'][-1]  # heurÃ­stica\n",
    "                transform = 'copy' if len(item['origin_cols'])==1 and item['expr'].strip() in item['origin_cols'] else item['expr']\n",
    "                rec = {\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'consulta': stmt,\n",
    "                    'tabla_origen': resolve_table_from_token(origin if origin else (item['origin_cols'][-1] if item['origin_cols'] else None), src_tables),\n",
    "                    'tabla_destino': target_table,\n",
    "                    'campo_origen': (origin if (not origin or origin=='*') else origin.split('.')[-1]),\n",
    "                    'campo_destino': (dest_col if (not dest_col or dest_col=='*') else dest_col.split('.')[-1]),\n",
    "                    'transformacion_aplicada': transform,\n",
    "                    'recomendaciones': 'mapping por posicion entre select y lista de columnas destino'\n",
    "                }\n",
    "                results.append(rec)\n",
    "        else:\n",
    "            # no se especifica lista destino, inferimos destino por alias/nombre\n",
    "            for item in items:\n",
    "                dest_col = item['alias'] if item['alias'] else (item['origin_cols'][-1] if item['origin_cols'] else None)\n",
    "                origin = item['origin_cols'][-1] if item['origin_cols'] else None\n",
    "                transform = 'copy' if len(item['origin_cols'])==1 and item['expr'].strip() in item['origin_cols'] else item['expr']\n",
    "                rec = {\n",
    "                    'id': str(uuid.uuid4()),\n",
    "                    'consulta': stmt,\n",
    "                    'tabla_origen': resolve_table_from_token(origin if origin else (item['origin_cols'][-1] if item['origin_cols'] else None), src_tables),\n",
    "                    'tabla_destino': target_table,\n",
    "                    'campo_origen': (origin if (not origin or origin=='*') else origin.split('.')[-1]),\n",
    "                    'campo_destino': (dest_col if (not dest_col or dest_col=='*') else dest_col.split('.')[-1]),\n",
    "                    'transformacion_aplicada': transform,\n",
    "                    'recomendaciones': 'mapping inferido sin lista destino; se recomienda especificar columnas en el insert para mayor claridad'\n",
    "                }\n",
    "                results.append(rec)\n",
    "        return results\n",
    "\n",
    "    # -------------------------\n",
    "    # Caso con WITH ... (CTE) - tratar CTEs y luego buscar insert/create\n",
    "    # -------------------------\n",
    "    # heurÃ­stica: si comienza con with, extraemos CTEs y procesamos la sentencia principal recursivamente\n",
    "    if stmt.strip().startswith('with '):\n",
    "        cte_map_local = parse_ctes(stmt)\n",
    "        # extraer la parte principal buscando la primera palabra top-level que sea 'insert' o 'create' o 'select' despuÃ©s del bloque with\n",
    "        # encontraremos la posiciÃ³n de la palabra 'with' y luego buscaremos 'insert' o 'create' u 'select' top-level posterior\n",
    "        # para simplificar, buscamos 'insert' y 'create' top-level y tomamos la que ocurra primero\n",
    "        pos_insert = find_top_level_keyword(stmt, 'insert', 0)\n",
    "        pos_create = find_top_level_keyword(stmt, 'create', 0)\n",
    "        pos_select = find_top_level_keyword(stmt, 'select', 0)\n",
    "        # elegimos la mÃ­nima positiva > 0\n",
    "        candidates = [p for p in [pos_insert, pos_create, pos_select] if p and p > 0]\n",
    "        if candidates:\n",
    "            main_pos = min(candidates)\n",
    "            main_stmt = stmt[main_pos:]\n",
    "            # recursivamente parsear la main statement\n",
    "            return lineage_from_statement(main_stmt, cte_map_local)\n",
    "        else:\n",
    "            # no se pudo identificar main statement; devolver vacÃ­o o un registro general\n",
    "            rec = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'consulta': stmt,\n",
    "                'tabla_origen': None,\n",
    "                'tabla_destino': None,\n",
    "                'campo_origen': None,\n",
    "                'campo_destino': None,\n",
    "                'transformacion_aplicada': None,\n",
    "                'recomendaciones': 'with detectado pero no se pudo localizar la sentencia principal (insert/create/select) - revisar manualmente'\n",
    "            }\n",
    "            return [rec]\n",
    "\n",
    "    # -------------------------\n",
    "    # Otros casos: SELECT independiente => reporte tablas origen utilizadas\n",
    "    # -------------------------\n",
    "    select_items = extract_select_items(stmt)\n",
    "    if select_items:\n",
    "        from_clause = extract_from_clause(stmt)\n",
    "        src_tables = get_src_tables_with_ctes(from_clause, cte_map)\n",
    "        for (src_tab, alias) in src_tables:\n",
    "            rec = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'consulta': stmt,\n",
    "                'tabla_origen': src_tab,\n",
    "                'tabla_destino': None,\n",
    "                'campo_origen': None,\n",
    "                'campo_destino': None,\n",
    "                'transformacion_aplicada': None,\n",
    "                'recomendaciones': 'consulta select independiente; listado de tablas origen detectadas'\n",
    "            }\n",
    "            results.append(rec)\n",
    "        if results:\n",
    "            return results\n",
    "\n",
    "    # si no se pudo parsear nada\n",
    "    rec = {\n",
    "        'id': str(uuid.uuid4()),\n",
    "        'consulta': stmt,\n",
    "        'tabla_origen': None,\n",
    "        'tabla_destino': None,\n",
    "        'campo_origen': None,\n",
    "        'campo_destino': None,\n",
    "        'transformacion_aplicada': None,\n",
    "        'recomendaciones': 'no se detecto un patron insert/create/select reconocible; requerir parser avanzado o revisar manualmente'\n",
    "    }\n",
    "    return [rec]\n",
    "\n",
    "# -------------------------\n",
    "# FunciÃ³n principal pÃºblica\n",
    "# -------------------------\n",
    "\n",
    "def generar_linaje_impala(sql_text: str) -> list:\n",
    "    \"\"\"\n",
    "    Dado un texto sql (puede contener mÃºltiples sentencias) devuelve lista de registros de linaje.\n",
    "    \"\"\"\n",
    "    sql_norm = normalize_sql(sql_text)\n",
    "    stmts = split_statements_top_level(sql_norm)\n",
    "    all_results = []\n",
    "    for s in stmts:\n",
    "        if not s.strip():\n",
    "            continue\n",
    "        recs = lineage_from_statement(s)\n",
    "        # garantizar que todas las claves estÃ©n en minÃºscula y sin None problemÃ¡tico (dejamos None para campos vacÃ­os)\n",
    "        for r in recs:\n",
    "            # normalizar strings a minÃºsculas (si existen)\n",
    "            for k in ['consulta','tabla_origen','tabla_destino','campo_origen','campo_destino','transformacion_aplicada','recomendaciones']:\n",
    "                if k in r and isinstance(r[k], str):\n",
    "                    r[k] = r[k].lower()\n",
    "            all_results.append(r)\n",
    "    return all_results\n",
    "\n",
    "def guardar_linaje_en_json(datos, ruta='json/linaje.json'):\n",
    "    os.makedirs('json', exist_ok=True)\n",
    "    with open(ruta, 'w', encoding='utf-8') as f:\n",
    "        json.dump(datos, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# -------------------------\n",
    "# Ejemplos de uso / pruebas\n",
    "# -------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ejemplos = [\n",
    "        # insert con columnas explicitas\n",
    "        \"\"\"\n",
    "        insert into sbani.dest_table (id, nombre, telefono)\n",
    "        select t.id, t.full_name as nombre, t.phone from sbani.source_table t;\n",
    "        \"\"\",\n",
    "        # insert con star\n",
    "        \"\"\"\n",
    "        insert into sbani.dest_all\n",
    "        select * from sbani.source_all;\n",
    "        \"\"\",\n",
    "        # create table as select (ctas) sin columnas\n",
    "        \"\"\"\n",
    "        create table sbani.ctas_table as\n",
    "        select a.col1, b.col2 from sbani.tabla_a a join sbani.tabla_b b on a.id = b.id;\n",
    "        \"\"\",\n",
    "        # with ... insert ... as\n",
    "        \"\"\"\n",
    "        with cte as (\n",
    "           select id, valor from sbani.origen\n",
    "        )\n",
    "        insert into sbani.destino select id, valor from cte;\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    linajes = []\n",
    "    for idx, sql in enumerate(ejemplos, 1):\n",
    "        print(\"SQL ----\")\n",
    "        print(sql.strip())\n",
    "        lin = generar_linaje_impala(sql)\n",
    "        linajes.extend(lin)\n",
    "        print(\"Lineage JSON:\")\n",
    "        print(json.dumps(lin, indent=2, ensure_ascii=False))\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    # Guardar resultado en archivo JSON\n",
    "    guardar_linaje_en_json(linajes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
